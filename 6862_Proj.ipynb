{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usqcaOSEYyKV",
        "outputId": "82583cb5-ff05-4a54-e05f-fbcdbef8053d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.668\n",
            "ROC-AUC: 0.677122331807826\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.67      0.90      0.77      1221\n",
            "        True       0.66      0.31      0.42       779\n",
            "\n",
            "    accuracy                           0.67      2000\n",
            "   macro avg       0.66      0.60      0.59      2000\n",
            "weighted avg       0.67      0.67      0.63      2000\n",
            "\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.6625\n",
            "ROC-AUC: 0.6832364515291345\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.67      0.88      0.76      1221\n",
            "        True       0.63      0.33      0.43       779\n",
            "\n",
            "    accuracy                           0.66      2000\n",
            "   macro avg       0.65      0.60      0.60      2000\n",
            "weighted avg       0.65      0.66      0.63      2000\n",
            "\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.666\n",
            "ROC-AUC: 0.6834167578711867\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.69      0.82      0.75      1221\n",
            "        True       0.60      0.43      0.50       779\n",
            "\n",
            "    accuracy                           0.67      2000\n",
            "   macro avg       0.65      0.62      0.62      2000\n",
            "weighted avg       0.66      0.67      0.65      2000\n",
            "\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.668\n",
            "ROC-AUC: 0.710823847537583\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.68      0.86      0.76      1221\n",
            "        True       0.62      0.37      0.47       779\n",
            "\n",
            "    accuracy                           0.67      2000\n",
            "   macro avg       0.65      0.61      0.61      2000\n",
            "weighted avg       0.66      0.67      0.65      2000\n",
            "\n",
            "\n",
            "Sample Patient Recommendations:\n",
            "   Cluster                        Intervention_Recommendation\n",
            "0        0  High-risk intervention: Schedule frequent foll...\n",
            "1        1  Moderate-risk intervention: Educate patient on...\n",
            "2        1  Moderate-risk intervention: Educate patient on...\n",
            "3        0  High-risk intervention: Schedule frequent foll...\n",
            "4        0  High-risk intervention: Schedule frequent foll...\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '10k_diabetes (1).csv'  # Replace with your file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Selecting relevant columns and encoding categorical features\n",
        "columns_to_use = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id',\n",
        "                  'admission_source_id', 'time_in_hospital', 'num_lab_procedures',\n",
        "                  'num_medications', 'number_outpatient', 'number_emergency',\n",
        "                  'number_inpatient', 'number_diagnoses']\n",
        "\n",
        "X = data[columns_to_use].copy()\n",
        "y = data['readmitted']\n",
        "\n",
        "# Convert categorical columns to numeric using Label Encoding\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize numerical columns\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba)}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 1: Predict Patient Readmission Risk\n",
        "# Logistic Regression\n",
        "print(\"Logistic Regression:\")\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "evaluate_model(log_reg, X_test, y_test)\n",
        "\n",
        "# Decision Tree\n",
        "print(\"\\nDecision Tree:\")\n",
        "decision_tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "evaluate_model(decision_tree, X_test, y_test)\n",
        "\n",
        "# Random Forest\n",
        "print(\"\\nRandom Forest:\")\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest.fit(X_train, y_train)\n",
        "evaluate_model(random_forest, X_test, y_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "print(\"\\nGradient Boosting:\")\n",
        "gradient_boosting = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gradient_boosting.fit(X_train, y_train)\n",
        "evaluate_model(gradient_boosting, X_test, y_test)\n",
        "\n",
        "# Step 2: Clustering for Intervention Recommendation\n",
        "# Using KMeans clustering to identify patient segments\n",
        "num_clusters = 3\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "X_clustered = kmeans.fit_predict(X)\n",
        "\n",
        "# Assign recommended interventions based on clusters\n",
        "interventions = {\n",
        "    0: \"High-risk intervention: Schedule frequent follow-ups and monitor closely.\",\n",
        "    1: \"Moderate-risk intervention: Educate patient on self-management techniques.\",\n",
        "    2: \"Low-risk intervention: Provide standard discharge instructions.\"\n",
        "}\n",
        "\n",
        "# Add recommendations to the dataset\n",
        "X['Cluster'] = X_clustered\n",
        "X['Intervention_Recommendation'] = X['Cluster'].map(interventions)\n",
        "\n",
        "# Display sample recommendations\n",
        "sample_recommendations = X[['Cluster', 'Intervention_Recommendation']].head()\n",
        "print(\"\\nSample Patient Recommendations:\")\n",
        "print(sample_recommendations)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "\n",
        "# Define the neural network model architecture\n",
        "nn_model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # First hidden layer\n",
        "    Dense(32, activation='relu'),                             # Second hidden layer\n",
        "    Dense(1, activation='sigmoid')                            # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = nn_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1, validation_split=0.2)\n",
        "\n",
        "# Predict on the test data\n",
        "nn_predictions = (nn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\nNeural Network Accuracy:\", accuracy_score(y_test, nn_predictions))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, nn_model.predict(X_test)))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, nn_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DU6Tl1OchI6",
        "outputId": "9b24cfbe-d431-445f-9d88-9fbf108a9b23"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6147 - loss: 0.6510 - val_accuracy: 0.6237 - val_loss: 0.6477\n",
            "Epoch 2/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6475 - loss: 0.6328 - val_accuracy: 0.6237 - val_loss: 0.6447\n",
            "Epoch 3/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6555 - loss: 0.6292 - val_accuracy: 0.6319 - val_loss: 0.6430\n",
            "Epoch 4/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6578 - loss: 0.6160 - val_accuracy: 0.6300 - val_loss: 0.6427\n",
            "Epoch 5/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6632 - loss: 0.6170 - val_accuracy: 0.6300 - val_loss: 0.6451\n",
            "Epoch 6/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6581 - loss: 0.6191 - val_accuracy: 0.6356 - val_loss: 0.6454\n",
            "Epoch 7/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6697 - loss: 0.6118 - val_accuracy: 0.6381 - val_loss: 0.6458\n",
            "Epoch 8/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6700 - loss: 0.6008 - val_accuracy: 0.6363 - val_loss: 0.6455\n",
            "Epoch 9/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6662 - loss: 0.6114 - val_accuracy: 0.6300 - val_loss: 0.6479\n",
            "Epoch 10/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6770 - loss: 0.6006 - val_accuracy: 0.6319 - val_loss: 0.6478\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Neural Network Accuracy: 0.67\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "ROC-AUC Score: 0.6849790623859944\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.68      0.86      0.76      1221\n",
            "        True       0.63      0.37      0.47       779\n",
            "\n",
            "    accuracy                           0.67      2000\n",
            "   macro avg       0.66      0.62      0.61      2000\n",
            "weighted avg       0.66      0.67      0.65      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/10k_diabetes (1).csv'  # Update this path with the correct file path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Selecting relevant columns for input features\n",
        "columns_to_use = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id',\n",
        "                  'admission_source_id', 'time_in_hospital', 'num_lab_procedures',\n",
        "                  'num_medications', 'number_outpatient', 'number_emergency',\n",
        "                  'number_inpatient', 'number_diagnoses']\n",
        "\n",
        "X = data[columns_to_use].copy()\n",
        "y = data['readmitted']\n",
        "\n",
        "# Encode categorical variables\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the numerical columns for neural network\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Ensure y_train is in binary integer format (0 and 1)\n",
        "y_train = y_train.astype(int)  # Corrected: Convert to integers\n",
        "\n",
        "# Calculate class weights to handle imbalance\n",
        "unique_classes = np.unique(y_train)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=y_train)\n",
        "\n",
        "# Create class_weights_dict with integer keys\n",
        "class_weights_dict = {int(cls): weight for cls, weight in zip(unique_classes, class_weights)}\n",
        "\n",
        "print(\"Class Weights:\", class_weights_dict)  # Optional: To check computed weights\n",
        "\n",
        "# Define the neural network model with Input layer and additional dropout layers\n",
        "nn_model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # Input layer with the shape of the feature set\n",
        "    Dense(128, activation='relu'),     # First hidden layer with 128 neurons\n",
        "    Dropout(0.3),                      # Dropout layer to prevent overfitting\n",
        "    Dense(64, activation='relu'),      # Second hidden layer with 64 neurons\n",
        "    Dropout(0.3),                      # Dropout layer\n",
        "    Dense(32, activation='relu'),      # Third hidden layer with 32 neurons\n",
        "    Dense(1, activation='sigmoid')     # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with a reduced learning rate\n",
        "nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                 loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define EarlyStopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model with class weights and early stopping\n",
        "history = nn_model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=1,\n",
        "                       validation_split=0.2, class_weight=class_weights_dict,\n",
        "                       callbacks=[early_stopping])\n",
        "\n",
        "# Make predictions on the test set\n",
        "nn_predictions = (nn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\nEnhanced Neural Network Accuracy:\", accuracy_score(y_test, nn_predictions))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, nn_model.predict(X_test)))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, nn_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "NfRq7MVodUcf",
        "outputId": "600fbdb7-8375-4b18-e2d1-281e1c12c0e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 0.8309098462816784, 1: 1.2554927809165097}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8acf85c7eeaf>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Train the model with class weights and early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m history = nn_model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=1, \n\u001b[0m\u001b[1;32m     70\u001b[0m                        \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                        callbacks=[early_stopping])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}